{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import whisper\n",
    "import torch\n",
    "from dotenv import load_dotenv\n",
    "from sys import platform\n",
    "from time import sleep\n",
    "from tempfile import NamedTemporaryFile\n",
    "from queue import Queue\n",
    "from datetime import datetime, timedelta\n",
    "import speech_recognition as sr\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# last time a recording from retreived from queue\n",
    "phrase_time = None\n",
    "\n",
    "# current rawy audio bytes\n",
    "last_sample = bytes()\n",
    "\n",
    "# thread safe queue for passing data from the threaded recording callback\n",
    "data_queue = Queue()\n",
    "\n",
    "# SpeechRecognizer to record audio\n",
    "recorder = sr.Recognizer()\n",
    "recorder.energy_threshold = 1000\n",
    "\n",
    "# dynamic energy comp lowers energy threshold to a point where we're always recording\n",
    "recorder.dynamic_energy_threshold = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# record callback\n",
    "def record_callback(_, audio: sr.AudioData) -> None:\n",
    "    \"\"\"\n",
    "    Threaded callback func to receive audio data when recordings finish.\n",
    "    audio: An AudioData object containing recorded bytes.\n",
    "    \"\"\"\n",
    "    # raw bytes push it into thread safe queue\n",
    "    data = audio.get_raw_data()\n",
    "    data_queue.put(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "microphone_name = \"Microphone (2- USB PnP Audio Device)\"\n",
    "source = \"\"\n",
    "\n",
    "for index, name in enumerate(sr.Microphone.list_microphone_names()):\n",
    "    print(\n",
    "        'Microphone with name \"{1}\" found for `Microphone(device_index={0})`'.format(\n",
    "            index, name\n",
    "        )\n",
    "    )\n",
    "    if name == microphone_name:\n",
    "        source = sr.Microphone(sample_rate=16000, device_index=1)\n",
    "        # print(f\"Microphone {name} found at index {index}\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the whisper model\n",
    "audio_model = whisper.load_model(\"tiny.en\")\n",
    "\n",
    "record_timeout = 2\n",
    "phrase_timeout = 3\n",
    "\n",
    "temp_file = NamedTemporaryFile().name\n",
    "transcription = [\"\"]\n",
    "\n",
    "with source:\n",
    "    recorder.adjust_for_ambient_noise(source)\n",
    "\n",
    "# background thread that gives us raw bytes\n",
    "recorder.listen_in_background(source, record_callback, phrase_time_limit=record_timeout)\n",
    "\n",
    "# Signal user we're ready\n",
    "print(\"Model loaded...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main loop\n",
    "while True:\n",
    "    try:\n",
    "        now = datetime.utcnow()\n",
    "        # get raw record from queue\n",
    "        if not data_queue.empty():\n",
    "            phrase_complete = False\n",
    "            # if enough time has passed since last phrase - phrase is complete\n",
    "            # clear current audio buffer\n",
    "            if phrase_time and now - phrase_time > timedelta(seconds=phrase_timeout):\n",
    "                last_sample = bytes()\n",
    "                phrase_complete = True\n",
    "            # last time we received new audio from queue\n",
    "            phrase_time = now\n",
    "\n",
    "            # concatenate last sample with new sample\n",
    "            while not data_queue.empty():\n",
    "                data = data_queue.get()\n",
    "                last_sample += data\n",
    "\n",
    "            # use AudioData to convert raw data into wav file\n",
    "            audio_data = sr.AudioData(\n",
    "                last_sample, source.SAMPLE_RATE, source.SAMPLE_WIDTH\n",
    "            )\n",
    "            wav_data = io.BytesIO(audio_data.get_wav_data())\n",
    "\n",
    "            # write wav to file\n",
    "            with open(temp_file, \"w+b\") as f:\n",
    "                f.write(wav_data.read())\n",
    "\n",
    "            # read transcriptions from model\n",
    "            result = audio_model.transcribe(temp_file, fp16=torch.cuda.is_available())\n",
    "            text = result[\"text\"].strip()\n",
    "\n",
    "            # if we detect pauses between recordings, add new item to transcription list\n",
    "            # otherwise edit existing one\n",
    "            if phrase_complete:\n",
    "                transcription.append(text)\n",
    "            else:\n",
    "                transcription[-1] = text\n",
    "\n",
    "            # clear console to reprint transcriptions\n",
    "            os.system(\"cls\" if os.name == \"nt\" else \"clear\")\n",
    "            for line in transcription:\n",
    "                print(line)\n",
    "\n",
    "            # flush stout to make sure we see the transcriptions\n",
    "            print(\" \", end=\"\", flush=True)\n",
    "\n",
    "            # processor sleep\n",
    "            sleep(0.15)\n",
    "    except KeyboardInterrupt:\n",
    "        break\n",
    "\n",
    "    print(\"\\n\\nTranscription:\")\n",
    "    for line in transcription:\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "available_models = [x[\"id\"] for x in openai.Model.list()[\"data\"]]\n",
    "print(sorted(available_models))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "whisperme-inx_CwcD",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
