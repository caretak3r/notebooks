{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from supabase.client import Client, create_client\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import SupabaseVectorStore\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "load_dotenv()\n",
    "print(load_dotenv())\n",
    "\n",
    "supabase_url = os.environ.get(\"SUPABASE_URL\")\n",
    "supabase_key = os.environ.get(\"SUPABASE_SERVICE_KEY\")\n",
    "supabase: Client = create_client(supabase_url, supabase_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file: ChainGPT.sol\n",
      "file: ChainGPT.sol_flattened.sol\n",
      "file: compiler_config.json\n",
      "file: readme.md\n",
      "file: ChainGPT.json\n",
      "file: ChainGPT_metadata.json\n",
      "file: 3c8d2d39e478be63f86f987c03ca34a1.json\n"
     ]
    }
   ],
   "source": [
    "# configure these to fit your needs\n",
    "exclude_dir = [\".git\", \"node_modules\", \"public\", \"assets\"]\n",
    "exclude_files = [\"package-lock.json\", \".DS_Store\"]\n",
    "exclude_extensions = [\n",
    "    \".jpg\",\n",
    "    \".jpeg\",\n",
    "    \".png\",\n",
    "    \".gif\",\n",
    "    \".bmp\",\n",
    "    \".tiff\",\n",
    "    \".ico\",\n",
    "    \".svg\",\n",
    "    \".webp\",\n",
    "    \".mp3\",\n",
    "    \".wav\",\n",
    "]\n",
    "\n",
    "documents = []\n",
    "\n",
    "for dirpath, dirnames, filenames in os.walk(\"CGPT_Token\"):\n",
    "    # skip directories in exclude_dir\n",
    "    dirnames[:] = [d for d in dirnames if d not in exclude_dir]\n",
    "\n",
    "    for file in filenames:\n",
    "        print(f\"file: {file}\")\n",
    "        _, file_extension = os.path.splitext(file)\n",
    "\n",
    "        # skip files in exclude_files\n",
    "        if file not in exclude_files and file_extension not in exclude_extensions:\n",
    "            file_path = os.path.join(dirpath, file)\n",
    "            loader = TextLoader(file_path, encoding=\"ISO-8859-1\")\n",
    "            documents.extend(loader.load())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# split the text \n",
    "# create chunks for the vector database\n",
    "# insert into db "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = CharacterTextSplitter(chunk_size=2000, chunk_overlap=200)\n",
    "docs = text_splitter.split_documents(documents)\n",
    "\n",
    "for doc in docs:\n",
    "    source = doc.metadata[\"source\"]\n",
    "    cleaned_source = \"/\".join(source.split(\"/\")[1:])\n",
    "    doc.page_content = (\n",
    "        \"FILE NAME: \"\n",
    "        + cleaned_source\n",
    "        + \"\\n###\\n\"\n",
    "        + doc.page_content.replace(\"\\u0000\", \"\")\n",
    "    )\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "print(os.environ.get(\"TABLE_NAME\"))\n",
    "\n",
    "vector_store = SupabaseVectorStore.from_documents(\n",
    "    docs, embeddings, client=supabase, table_name=os.environ.get(\"TABLE_NAME\")\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# now we setup to ask the db/table questions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "textualize-paper-qa-FwPdbxm8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
